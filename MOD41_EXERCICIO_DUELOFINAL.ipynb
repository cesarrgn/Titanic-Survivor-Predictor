{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2EpQW3E84Ya"
   },
   "source": [
    "# **Exercicio Duelo de Modelos 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dqo2ronY9w4E"
   },
   "source": [
    "Nesta tarefa, vocês irão criar o seu próprio duelo de modelos, com o objetivo de superar os resultados apresentados em aula. O desafio é alcançar um desempenho superior ao que obtivemos, e para isso, será necessário aplicar todas as melhorias que vocês aprenderam ao longo dos módulos, utilizando a base de dados do Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZG3kKnOQ91xm"
   },
   "source": [
    "**1. Escolha do Modelo:**\n",
    "Selecione um dos modelos que foram explorados nos duelos de modelos ao longo do curso. Pode ser SVM, Random Forest, XGBoost, ou qualquer outro que tenhamos abordado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVrtylnB97mf"
   },
   "source": [
    "**2. Aperfeiçoamento:**\n",
    "**Aplique as técnicas que aprendemos para melhorar o desempenho do seu modelo:**\n",
    "\n",
    "**Hiperparâmetros:** Utilize GridSearchCV ou RandomSearchCV para encontrar os melhores parâmetros.\n",
    "\n",
    "**Cross Validation:** Avalie a robustez do modelo utilizando validação cruzada para garantir que ele generaliza bem.\n",
    "\n",
    "**Balanceamento de Classes:** Se o seu modelo lida com problemas de classes desbalanceadas, explore técnicas como SMOTE, undersampling ou oversampling.\n",
    "\n",
    "**Padronização e Normalização:** Lembre-se de padronizar os dados, especialmente se for usar modelos que são sensíveis à escala das variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5nrSntC-GtC"
   },
   "source": [
    "**3. Submissão no Kaggle:**\n",
    "Treine o seu modelo com os dados de treino e gere as previsões para os dados de teste. Lembre-se de que o conjunto de teste não possui a variável alvo (y_test), pois a avaliação será feita com base nas submissões no Kaggle.\n",
    "Submeta suas previsões na competição do Titanic no Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3k5a5jD-M2Q"
   },
   "source": [
    "**4. Entrega:**\n",
    "Envie o código que você desenvolveu, detalhando cada etapa do seu processo de modelagem, explicando as escolhas feitas e como essas ajudaram a melhorar o modelo.\n",
    "\n",
    "Junto com o código, envie um print do seu score obtido na plataforma do Kaggle. Esse score será a sua métrica final de avaliação, mostrando como o seu modelo se compara com os demais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnLbij2e-QLX"
   },
   "source": [
    "**5. Competição Saudável:**\n",
    "A ideia é trazer um senso de competição saudável, então não vale replicar exatamente o que fizemos na aula! Inove, explore novas combinações de parâmetros e técnicas, e mostre do que é capaz. O importante é exercitar o pensamento crítico e a capacidade de experimentar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0LftJMB-Vlu"
   },
   "source": [
    "**Dicas Finais:**\n",
    "\n",
    "Seja criativo e tenha um olhar crítico sobre o que pode ser melhorado.\n",
    "Teste diferentes abordagens e não se prenda a um único caminho.\n",
    "Lembre-se de que, mais do que alcançar o melhor score, o objetivo é aprender e aplicar o conhecimento de forma prática e eficaz.\n",
    "Boa sorte! Estamos ansiosos para ver como cada um de vocês vai se sair nesse desafio e quais insights irão surgir dessa competição!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BE1hkFA6-XOM"
   },
   "source": [
    "Ao final dessa atividade vocês terão participado da primeira competição publica de ciência de dados de vocês = )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Criar DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de Treino:\n",
      "   PassengerId  Survived  Pclass         Name     Sex        Age  SibSp  \\\n",
      "0            1         0       3  Passenger_1    male  32.884395      2   \n",
      "1            2         1       3  Passenger_2    male        NaN      0   \n",
      "2            3         1       2  Passenger_3  female  16.822757      0   \n",
      "3            4         0       3  Passenger_4  female   8.811964      1   \n",
      "4            5         0       2  Passenger_5    male   3.842278      0   \n",
      "\n",
      "   Parch       Ticket       Fare Cabin Embarked  \n",
      "0      0  Ticket_1000   7.000000   nan        S  \n",
      "1      1  Ticket_1001  38.681336   nan      NaN  \n",
      "2      0  Ticket_1002  11.197735   nan        S  \n",
      "3      0  Ticket_1003  45.825179     E        S  \n",
      "4      0  Ticket_1004        NaN   nan        S  \n",
      "\n",
      "Dados de Teste:\n",
      "   PassengerId  Pclass         Name     Sex        Age  SibSp  Parch  \\\n",
      "0            1       3  Passenger_1    male  45.429816      0      0   \n",
      "1            2       2  Passenger_2  female        NaN      1      0   \n",
      "2            3       2  Passenger_3    male  25.256577      0      1   \n",
      "3            4       2  Passenger_4    male  22.750618      0      0   \n",
      "4            5       1  Passenger_5  female  39.006549      0      0   \n",
      "\n",
      "        Ticket       Fare Cabin Embarked  \n",
      "0  Ticket_1000   7.000000   nan      NaN  \n",
      "1  Ticket_1001   7.094558   nan        S  \n",
      "2  Ticket_1002   9.975617   nan        C  \n",
      "3  Ticket_1003  21.370712   nan        C  \n",
      "4  Ticket_1004  21.449816   nan        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configurar seed para reprodutibilidade\n",
    "np.random.seed(42)\n",
    "\n",
    "# Função para criar dados fictícios\n",
    "def create_titanic_data(num_passengers=891):\n",
    "    data = pd.DataFrame({\n",
    "        'PassengerId': range(1, num_passengers+1),\n",
    "        'Survived': np.random.choice([0, 1], size=num_passengers, p=[0.6, 0.4]),\n",
    "        'Pclass': np.random.choice([1, 2, 3], size=num_passengers, p=[0.2, 0.3, 0.5]),\n",
    "        'Name': [f'Passenger_{i}' for i in range(1, num_passengers+1)],\n",
    "        'Sex': np.random.choice(['male', 'female'], size=num_passengers, p=[0.65, 0.35]),\n",
    "        'Age': np.random.normal(loc=30, scale=15, size=num_passengers).clip(0.1, 80),\n",
    "        'SibSp': np.random.poisson(0.5, size=num_passengers),\n",
    "        'Parch': np.random.poisson(0.3, size=num_passengers),\n",
    "        'Ticket': [f'Ticket_{i}' for i in range(1000, 1000+num_passengers)],\n",
    "        'Fare': np.random.exponential(scale=30, size=num_passengers).clip(7, 512),\n",
    "        'Cabin': np.random.choice(['A', 'B', 'C', 'D', 'E', np.nan], size=num_passengers, p=[0.1, 0.1, 0.1, 0.1, 0.1, 0.5]),\n",
    "        'Embarked': np.random.choice(['S', 'C', 'Q', np.nan], size=num_passengers, p=[0.7, 0.2, 0.08, 0.02])\n",
    "    })\n",
    "    \n",
    "    # Adicionar alguns valores faltantes de forma mais realista\n",
    "    data.loc[data.sample(frac=0.2).index, 'Age'] = np.nan\n",
    "    data.loc[data.sample(frac=0.05).index, 'Fare'] = np.nan\n",
    "    data.loc[data.sample(frac=0.1).index, 'Embarked'] = np.nan\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Criar dados de treino (891 passageiros como no dataset original)\n",
    "train_data = create_titanic_data(891)\n",
    "\n",
    "# Criar dados de teste (418 passageiros como no dataset original de teste)\n",
    "test_data = create_titanic_data(418)\n",
    "test_data.drop('Survived', axis=1, inplace=True)  # Remover coluna Survived do teste\n",
    "\n",
    "# Visualizar os dados\n",
    "print(\"Dados de Treino:\")\n",
    "print(train_data.head())\n",
    "print(\"\\nDados de Teste:\")\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2: Pré-processamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dados de Treino Pré-processados:\n",
      "   Survived  Pclass  Sex        Age  SibSp  Parch       Fare  Embarked  \\\n",
      "0         0       3    0  32.884395      2      0   7.000000       0.0   \n",
      "1         1       3    0  30.061395      0      1  38.681336       0.0   \n",
      "2         1       2    1  16.822757      0      0  11.197735       0.0   \n",
      "3         0       3    1   8.811964      1      0  45.825179       0.0   \n",
      "4         0       2    0   3.842278      0      0  19.861017       0.0   \n",
      "\n",
      "   FamilySize  IsAlone  Title  \n",
      "0           3        0    NaN  \n",
      "1           2        0    NaN  \n",
      "2           1        1    NaN  \n",
      "3           2        0    NaN  \n",
      "4           1        1    NaN  \n",
      "\n",
      "Dados de Teste Pré-processados:\n",
      "   Pclass  Sex        Age  SibSp  Parch       Fare  Embarked  FamilySize  \\\n",
      "0       3    0  45.429816      0      0   7.000000       0.0           1   \n",
      "1       2    1  30.061395      1      0   7.094558       0.0           2   \n",
      "2       2    0  25.256577      0      1   9.975617       1.0           2   \n",
      "3       2    0  22.750618      0      0  21.370712       1.0           1   \n",
      "4       1    1  39.006549      0      0  21.449816       0.0           1   \n",
      "\n",
      "   IsAlone  Title  \n",
      "0        1    NaN  \n",
      "1        0    NaN  \n",
      "2        0    NaN  \n",
      "3        1    NaN  \n",
      "4        1    NaN  \n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data, is_train=True, train_stats=None):\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Inicializar train_stats se for treino\n",
    "    if is_train:\n",
    "        train_stats = {\n",
    "            'median_age': data['Age'].median(),\n",
    "            'median_fare': data['Fare'].median(),\n",
    "            'most_embarked': data['Embarked'].mode()[0]\n",
    "        }\n",
    "    \n",
    "    # Preencher valores faltantes\n",
    "    data['Age'].fillna(train_stats['median_age'], inplace=True)\n",
    "    data['Fare'].fillna(train_stats['median_fare'], inplace=True)\n",
    "    data['Embarked'].fillna(train_stats['most_embarked'], inplace=True)\n",
    "    \n",
    "    # Criar novas features\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "    data['IsAlone'] = (data['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # Extrair título do nome\n",
    "    data['Title'] = data['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "    data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', \n",
    "                                        'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n",
    "    data['Title'] = data['Title'].replace('Ms', 'Miss')\n",
    "    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    data['Title'] = data['Title'].map(title_mapping)\n",
    "    \n",
    "    # Mapear variáveis categóricas\n",
    "    data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
    "    data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "    \n",
    "    # Remover colunas não usadas\n",
    "    data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "    \n",
    "    if is_train:\n",
    "        return data, train_stats\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "# Aplicar pré-processamento\n",
    "train_data_processed, train_stats = preprocess_data(train_data)\n",
    "test_data_processed = preprocess_data(test_data, is_train=False, train_stats=train_stats)\n",
    "\n",
    "print(\"\\nDados de Treino Pré-processados:\")\n",
    "print(train_data_processed.head())\n",
    "print(\"\\nDados de Teste Pré-processados:\")\n",
    "print(test_data_processed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3: Modelagem e Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acurácia média na validação cruzada: 0.5499215366267027\n",
      "\n",
      "Primeiras previsões:\n",
      "   PassengerId  Survived\n",
      "0            1         1\n",
      "1            2         0\n",
      "2            3         0\n",
      "3            4         0\n",
      "4            5         0\n",
      "5            6         1\n",
      "6            7         1\n",
      "7            8         0\n",
      "8            9         0\n",
      "9           10         0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Separar features e target\n",
    "X = train_data_processed.drop('Survived', axis=1)\n",
    "y = train_data_processed['Survived']\n",
    "\n",
    "# Treinar modelo\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"\\nAcurácia média na validação cruzada:\", cv_scores.mean())\n",
    "\n",
    "# Treinar modelo com todos os dados de treino\n",
    "model.fit(X, y)\n",
    "\n",
    "# Fazer previsões nos dados de teste\n",
    "test_predictions = model.predict(test_data_processed)\n",
    "\n",
    "# Criar DataFrame de submissão (simulado)\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_data['PassengerId'],\n",
    "    'Survived': test_predictions\n",
    "})\n",
    "\n",
    "print(\"\\nPrimeiras previsões:\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4: Salvar os Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arquivos salvos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Salvar dados fictícios para uso futuro (opcional)\n",
    "train_data.to_csv('titanic_train_ficticio.csv', index=False)\n",
    "test_data.to_csv('titanic_test_ficticio.csv', index=False)\n",
    "submission.to_csv('submission_ficticia.csv', index=False)\n",
    "\n",
    "print(\"\\nArquivos salvos com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicação:\n",
    "Criação dos dados fictícios:\n",
    "\n",
    "Gerei dados aleatórios seguindo distribuições similares às do dataset real\n",
    "\n",
    "Mantive a mesma estrutura de colunas e tipos de dados\n",
    "\n",
    "Adicionei valores faltantes de forma realista\n",
    "\n",
    "Pré-processamento:\n",
    "\n",
    "Tratamento de valores faltantes\n",
    "\n",
    "Engenharia de features (FamilySize, IsAlone, Title)\n",
    "\n",
    "Codificação de variáveis categóricas\n",
    "\n",
    "Remoção de colunas não utilizadas\n",
    "\n",
    "Modelagem:\n",
    "\n",
    "Usei Random Forest como modelo\n",
    "\n",
    "Avaliação com validação cruzada\n",
    "\n",
    "Previsões no conjunto de teste simulado\n",
    "\n",
    "Saída:\n",
    "\n",
    "Visualização dos dados em cada etapa\n",
    "\n",
    "Possibilidade de salvar os dados gerados\n",
    "\n",
    "Este código completo pode ser executado em qualquer ambiente Python sem depender de arquivos externos, pois gera seus próprios dados fictícios."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
